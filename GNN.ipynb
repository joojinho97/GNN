{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4be936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_structured_learning as nsl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23adc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39980441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /home/jhjoo/anaconda3/lib/libuuid.so.1: no version information available (required by wget)\r\n"
     ]
    }
   ],
   "source": [
    "!wget --quiet -P /tmp https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eacb68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora/\r\n",
      "cora/README\r\n",
      "cora/cora.cites\r\n",
      "cora/cora.content\r\n"
     ]
    }
   ],
   "source": [
    "!tar -C /tmp -xvzf /tmp/cora.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dacaac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet neural-structured-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adaed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /home/jhjoo/anaconda3/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2023-03-13 12:24:30--  https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11640 (11K) [text/plain]\n",
      "Saving to: ‘preprocess_cora_dataset.py’\n",
      "\n",
      "preprocess_cora_dat 100%[===================>]  11.37K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-03-13 12:24:30 (18.3 MB/s) - ‘preprocess_cora_dataset.py’ saved [11640/11640]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25eb922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = './cora/train_merged_examples.tfr'\n",
    "TEST_DATA_PATH = './cora/test_examples.tfr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c36067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
    "NBR_WEIGHT_SUFFIX = '_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d119527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "  \"\"\"Hyperparameters used for training.\"\"\"\n",
    "  def __init__(self):\n",
    "    ### dataset parameters\n",
    "    self.num_classes = 7\n",
    "    self.max_seq_length = 1433\n",
    "    ### neural graph learning parameters\n",
    "    self.distance_type = nsl.configs.DistanceType.L2\n",
    "    self.graph_regularization_multiplier = 0.1\n",
    "    self.num_neighbors = 1\n",
    "    ### model architecture\n",
    "    self.num_fc_units = [50, 50]\n",
    "    ### training parameters\n",
    "    self.train_epochs = 100\n",
    "    self.batch_size = 128\n",
    "    self.dropout_rate = 0.5\n",
    "    ### eval parameters\n",
    "    self.eval_steps = None  # All instances in the test set are evaluated.\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5af56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 09:48:11.082487: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-14 09:48:11.930131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 567 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(file_path, training=False):\n",
    "  \"\"\"Creates a `tf.data.TFRecordDataset`.\n",
    "\n",
    "  Args:\n",
    "    file_path: Name of the file in the `.tfrecord` format containing\n",
    "      `tf.train.Example` objects.\n",
    "    training: Boolean indicating if we are in training mode.\n",
    "\n",
    "  Returns:\n",
    "    An instance of `tf.data.TFRecordDataset` containing the `tf.train.Example`\n",
    "    objects.\n",
    "  \"\"\"\n",
    "\n",
    "  def parse_example(example_proto):\n",
    "    \"\"\"Extracts relevant fields from the `example_proto`.\n",
    "\n",
    "    Args:\n",
    "      example_proto: An instance of `tf.train.Example`.\n",
    "\n",
    "    Returns:\n",
    "      A pair whose first value is a dictionary containing relevant features\n",
    "      and whose second value contains the ground truth label.\n",
    "    \"\"\"\n",
    "    # The 'words' feature is a multi-hot, bag-of-words representation of the\n",
    "    # original raw text. A default value is required for examples that don't\n",
    "    # have the feature.\n",
    "    feature_spec = {\n",
    "        'words':\n",
    "            tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
    "                                  tf.int64,\n",
    "                                  default_value=tf.constant(\n",
    "                                      0,\n",
    "                                      dtype=tf.int64,\n",
    "                                      shape=[HPARAMS.max_seq_length])),\n",
    "        'label':\n",
    "            tf.io.FixedLenFeature((), tf.int64, default_value=-1),\n",
    "    }\n",
    "    # We also extract corresponding neighbor features in a similar manner to\n",
    "    # the features above during training.\n",
    "    if training:\n",
    "      for i in range(HPARAMS.num_neighbors):\n",
    "        nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
    "        nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i,\n",
    "                                         NBR_WEIGHT_SUFFIX)\n",
    "        feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
    "            [HPARAMS.max_seq_length],\n",
    "            tf.int64,\n",
    "            default_value=tf.constant(\n",
    "                0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
    "\n",
    "        # We assign a default value of 0.0 for the neighbor weight so that\n",
    "        # graph regularization is done on samples based on their exact number\n",
    "        # of neighbors. In other words, non-existent neighbors are discounted.\n",
    "        feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
    "            [1], tf.float32, default_value=tf.constant([0.0]))\n",
    "\n",
    "    features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "    label = features.pop('label')\n",
    "    return features, label\n",
    "\n",
    "  dataset = tf.data.TFRecordDataset([file_path])\n",
    "  if training:\n",
    "    dataset = dataset.shuffle(10000)\n",
    "  dataset = dataset.map(parse_example)\n",
    "  dataset = dataset.batch(HPARAMS.batch_size)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
    "test_dataset = make_dataset(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539d31c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=({'NL_nbr_0_weight': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), 'NL_nbr_0_words': TensorSpec(shape=(None, 1433), dtype=tf.int64, name=None), 'words': TensorSpec(shape=(None, 1433), dtype=tf.int64, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9131447c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[5 1 0 2 4 6 4 0 3 1 2 2 3 0 2 6 0 5 4 6 3 3 3 4 4 2 6 0 6 2 6 1 5 4 0 5 1\n",
      " 2 5 4 3 2 1 2 2 2 1 4 4 2 5 3 2 5 6 3 4 6 2 2 6 1 2 1 3 1 1 1 3 5 3 2 1 2\n",
      " 1 2 1 2 2 1 2 4 4 3 3 3 3 1 0 3 0 2 6 6 5 6 2 5 2 6 1 2 2 2 0 5 2 6 2 3 2\n",
      " 3 3 3 1 4 4 4 6 2 3 1 2 3 1 1 0 1], shape=(128,), dtype=int64)\n",
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[2 2 3 1 3 0 6 3 6 2 0 2 5 3 2 2 3 3 2 6 0 3 5 2 2 2 4 0 3 4 2 2 3 1 2 3 2\n",
      " 6 2 3 2 2 2 0 1 1 2 2 1 2 2 1 6 2 2 2 0 3 3 0 2 4 0 2 1 4 2 5 2 2 2 3 4 1\n",
      " 4 0 1 6 2 6 6 3 2 3 2 6 1 3 3 3 6 3 3 6 0 2 2 0 2 4 2 1 1 0 4 1 2 6 5 1 3\n",
      " 6 3 2 1 1 1 3 0 0 3 3 5 0 5 0 0 6], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_dataset.take(2):\n",
    "  #print(feature_batch)\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40eaf1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of inputs: tf.Tensor([0 0 0 ... 0 0 0], shape=(1433,), dtype=int64)\n",
      "Batch of labels: tf.Tensor(\n",
      "[5 2 2 2 1 2 6 3 2 3 6 1 3 6 4 4 2 3 3 0 2 0 5 2 1 0 6 3 6 4 2 2 3 0 4 2 2\n",
      " 2 2 3 2 2 2 0 2 2 2 2 4 2 3 4 0 2 6 2 1 4 2 0 0 1 4 2 6 0 5 2 2 3 2 5 2 5\n",
      " 2 3 2 2 2 2 2 6 6 3 2 4 2 6 3 2 2 6 2 4 2 2 1 3 4 6 0 0 2 4 2 1 3 6 6 2 6\n",
      " 6 6 1 4 6 4 3 6 6 0 0 2 6 2 4 0 0], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in test_dataset.take(1):\n",
    "  #print('Feature list:', list(feature_batch.keys()))\n",
    "  np.savetxt('sample.csv', feature_batch['words'][0].numpy(), delimiter=\",\")\n",
    "  print('Batch of inputs:', feature_batch['words'][0])\n",
    "  print('Batch of labels:', label_batch)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58319515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp_functional_model(hparams):\n",
    "  \"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
    "  inputs = tf.keras.Input(\n",
    "      shape=(hparams.max_seq_length,), dtype='int64', name='words')\n",
    "\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  cur_layer = tf.keras.layers.Lambda(\n",
    "      lambda x: tf.keras.backend.cast(x, tf.float32))(\n",
    "          inputs)\n",
    "\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
    "\n",
    "    cur_layer = tf.keras.layers.Dropout(hparams.dropout_rate)(cur_layer)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(\n",
    "      hparams.num_classes, activation='softmax')(\n",
    "          cur_layer)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b006b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words (InputLayer)          [(None, 1433)]            0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 1433)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                71700     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,607\n",
      "Trainable params: 74,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = make_mlp_functional_model(HPARAMS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10aa27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model_desc, eval_metrics):\n",
    "  \"\"\"Prints evaluation metrics.\n",
    "\n",
    "  Args:\n",
    "    model_desc: A description of the model.\n",
    "    eval_metrics: A dictionary mapping metric names to corresponding values. It\n",
    "      must contain the loss and accuracy metrics.\n",
    "  \"\"\"\n",
    "  print('\\n')\n",
    "  print('Eval accuracy for ', model_desc, ': ', eval_metrics['accuracy'])\n",
    "  print('Eval loss for ', model_desc, ': ', eval_metrics['loss'])\n",
    "  if 'graph_loss' in eval_metrics:\n",
    "    print('Eval graph loss for ', model_desc, ': ', eval_metrics['graph_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7abd5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b86a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 09:49:22.007595: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2023-03-14 09:49:22.007654: E tensorflow/stream_executor/cuda/cuda_blas.cc:234] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-03-14 09:49:22.007688: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/dense_3/MatMul' defined at (most recent call last):\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_41371/3139996039.py\", line 1, in <module>\n      base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/layers/core/dense.py\", line 219, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_1/dense_3/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_1/dense_3/MatMul}}]] [Op:__inference_train_function_2084]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41371/3139996039.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecg/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/dense_3/MatMul' defined at (most recent call last):\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_41371/3139996039.py\", line 1, in <module>\n      base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhjoo/anaconda3/envs/ecg/lib/python3.7/site-packages/keras/layers/core/dense.py\", line 219, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_1/dense_3/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_1/dense_3/MatMul}}]] [Op:__inference_train_function_2084]"
     ]
    }
   ],
   "source": [
    "base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = dict(\n",
    "    zip(base_model.metrics_names,\n",
    "        base_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('Base MLP model', eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2581c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
